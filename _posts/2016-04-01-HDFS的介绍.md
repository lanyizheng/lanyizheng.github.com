#HDFS的介绍
Hadoop是一个分布式文件系统，其中包括了两大核心内容：

1. 并行计算框架MapReduce
2. 分布式存储系统HDFS

在这篇博客中，主要介绍HDFS。HDFS是Google的GFS(Google File System)的开源实现，是一个典型的主从架构的模型系统。

##1.基本概念

###1.1 NameNode
HDFS采用Master/Slave架构，NameNode就是其中的Master,主要负责HDFS文件系统的管理工作，包括名称空间管理，文件Block管理。

NameNode提供的是始终被动接收服务的server,主要有三类协议接口：

1. ClientProtocol接口：提供给客户端，用于访问NameNode,它包含了文件的HDFS功能
2. DataNodeProtocol接口：用于DataNode向NameNode通信
3. NameNodeProtocol:用于从NameNode到NameNode的通信。

在HDFS中，一个文件被分成一个或多个Block，这些Block存储在DataNode集合里，NameNode负责文件Block的所有元数据信息，这些元数据信息为：

	1.“文件 -> 数据块”映射
	2.“数据块 -> DataNode” 映射

NameNode上不保存 “数据块 -> DataNode列表”映射，该列表是通过DataNode上报给NameNode建立起来的。

我们一般启动hadoop所有进程的时候会发现还有一个SecongdNameNode,它主要是定时对NameNode的数据进行定时snapshots备份的。

###1.2 DataNode

DataNode就是负责存储数据的组件，一个数据块会在多个DataNode中进行冗余备份。DataNode上存储了数据块ID和数据块内容，以及它们的映射关系，一个HDFS可能包含上千个DataNode，这些DataNode定时与NameNode进行通信，为了减轻NameNode负担，NameNode上永远不保存哪个DataNode上有哪些数据块信息，而是通过DataNode启动时的上报来更新NameNode上的映射表。

###1.3 客户端
访问HDFS的程序或者HDFS的shell又可以称作HDFS客户端，在HDFS客户端中至少需要指定HDFS集群配置的NameNode地址和端口号信息，或者通过配置core-site.xml来指定。

###1.4 块
Data block是文件系统读写的最小数据单元，一般在文件系统中数据块的大小是512Byte。HDFS中也有数据块的改变，为了满足大数据的效率和整个集群的吞吐量选择了更大的数值，默认为64MB。客户端在读取HDFS上的一个文件时就以块为基本的数据单位。

##2.HDFS读过程

在HDFS系统中，读取文件主要分为以下几个步骤：
	
	1）调用FileSystem的open()打开文件
	2）DistributedFileSystem使用RPC调用NameNode,得到文件的数据块的元数据信息，并返回FSDataInputStream给客户端
	3）HDFS客户端调用用stream的read()函数开始读取数据
	4）调用FSDataInputStream直接从DataNode获取文件数据块，过程4、5
	5）读完文件，调用FSDataInputStream的close()函数，过程6

下面是HDFS中读文件数据的过程
![Alt text](/images/read.png)

##3.HDFS写过程
主要有以下几个步骤：
	
	1）客户端调用create()函数来创建文件
	2）DistributedFileSystem使用RPC调用NameNode元数据节点，在文件系统的命名空间中创建一个新的文件。（检查文件不存在，以及客户端有创建的权限），返回FSDataOutputStream,用于客户端写数据
	3）FSDataOutputStream将数据分成块，写入DataQueue。DataQueue由Data Streamer创建，并通知元数据节点分配数据节点，用来存储数据块(每块默认复制三份)
	4）分配的数据节点放在一个pipeline里，Data Streamer将数据块写入pipeline的第一个数据节点中，第一个数据节点将数据块发送给第二节点，第二个数据节点将数据块发送给第三个数据节点。
	5）FSDataOutputStream为发出去的数据块保存了Ack Queue，等待pipeline中的数据节点告知数据已经写入成功
	6）如果数据节点在写入过程中失败，则关闭pipeline,同时将Ack Queue中的数据块放入DataQueue的开始位置；当客户端结束写入数据，则调用close函数。


下面是HDFS写文件的过程图：
![Alt text](/images/write.png)


##4.数据组织

在客户端创建文件的请求并没有立即发送给DataNode,事实上，HDFS客户端会将文件数据缓存到本地的一个临时文件中，应用写文件时会被透明的重定向到这个临时文件。

当这个临时文件积累的数据超过一个Block的大小（默认64MB）,客户端才会联系NameNode,NameNode会将文件名插入文件系统中的层次结构，并且分配一个数据块给它，然后返回DataNode的标识数和目标数据块给客户端，客户端将本地临时文件flush到指定的DataNode上，当文件关闭时，在临时文件中剩余的没有被flush的数据也会传输到指定的DataNode上，然后客户端告诉NameNode文件已经关闭，此时NameNode才将文件创建操作提交到持久存储。


##5.空间回收

当文件或应用删除某个文件时，这个文件并没有立即从HDFS总是删除，而是将这个文件重命名，并转移到trash目录下，文件在trash目录中保存的时间是可以设置的，当超过设定时间后，NameNode就会将该文件从namespace中删除，同释放该文件的数据块。


##6.HDFS的使用
HDFS和Linux文件系统一样，有类似的命令行接口，所有的命令均由bin/hadoop脚本引发。

通常用法：

```
hadoop [--config confdir] command
#configdir覆盖默认配置目录，默认配置是${HADOOP_HOME}/conf
```

下面是一些常用命令：

```
1.cat
	hadoop fs -cat hdfs://host:port/data/part-0000
	hadoop fs -cat /data/part-0000   #可以不指定HDFS主机的host和port,采用默认的fs.default.name
	hadoop fs -cat file:///data/part-0000 #查看本地文件
2.ls
3.chgrp:修改文件所属的组
4.chmod：改变文件的权限
5.chown:改变文件拥有者
6.copyFromLocal:将本地文件放置在HDFS上，和put相似
	hadoop fs -copyFromLocal <localsrc> URI
7.copyToLocal:将HDFS上的文件复制到本地文件系统中，除了限定目标路径是一个本地文件外和get命令类似
	hadoop fs -copyFromLocal [-ignorecrc] [-crc] URI <localsrc>
8.get
9.mkdir
10.lsr:ls命令的递归版本
11.rmr:rm的递归版本
12.test
	hadoop fs -test -[ezd] URI
	-e: 检查文件是否存在，存在则返回0
	-z: 检查文件是否是0字节，如果是则返回0
	-d: 检查路径是否是目录，如果是则返回0，如果不是则返回-1
13.text
	hadoop fs -text <src> 将源文件输出为文本格式
```

