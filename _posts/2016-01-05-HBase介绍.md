    
#HBase 介绍

**HBase**是一个构建在Hadoop之上的非关系型数据库，是一种分布式的，可扩展，大数据存储。

----
##1.数据模型

在这一个章节，我将重点介绍在HBase中的一些概念和术语，比如:table,row,columns,Column Family,Cells。

###1.1 一些概念

以Mysql为例，我们知道数据库中有 database,table,columns,row等这些概念，对应在HBase中也有这些概念，只是在一些地方会有一些差别。
差异性表现在：

- 1.HBase中对应database 的概念是namespace
- 2.HBase中增加了ColumnFamily的概念
- 3.HBase的行列存储与Mysql的存储方式不一样

下面是HBase的一些概念:

- 1.Table:包含多行
- 2.Row:包含一个Row key和一个或多列的值
- 3.Column Family:列和列值的集合
- 4.Column Qualifier:属于列族，提供数据的索引
- 5.Cell:行,列族，列，时间戳，值的结合。
- 6.TimeStamp:时间戳，随着值写入

举个例子：

```
// 在表'scores'中,row key为'Tom'，列族为:course，列为：math，插入数值97
>>> put ‘scores','Tom','course:math','97′
//获取表't1',行键为'r1',列为'c1',TimeStamp在ts1,ts2之间的数值
>>> get ‘t1′, ‘r1′, {COLUMN => ‘c1′, TIMERANGE => [ts1, ts2], VERSIONS => 4} 
//创建命名空间
>>> create_namespace 'my_ns'
//创建表,指定列族
>>> create 'my_ns:my_table','cf1'
```

说明:

- 1.`HBase中每一行所包含的列数并不是一致的，比如'r1'行包含4列，'r2'行包含两列`
- 2.`我们在Mysql中通过sql语句创建表，这里把每一列都定义好了，但是在HBase中，只需要给定表名和列族就可以了(命名空间可以加)`
 
 下面一张图可以看到基本的表结构:
 
 ![webTable](/images/hbase_pic_1.png)
 
下面的JSON格式可以看到他们的层级关系：

```
{
  "com.cnn.www": {
    contents: {
      t6: contents:html: "<html>..."
      t5: contents:html: "<html>..."
      t3: contents:html: "<html>..."
    }
    anchor: {
      t9: anchor:cnnsi.com = "CNN"
      t8: anchor:my.look.ca = "CNN.com"
    }
    people: {}
  }
  "com.example.www": {
    contents: {
      t5: contents:html: "<html>..."
    }
    anchor: {}
    people: {
      t5: people:author: "John Doe"
    }
  }
}
```

###1.2 数据操作
四种基本的数据模型操作是：**Get,Put,Scan,Delete**

 操作说明：
 
 - 1.Get:返回指定的一行数据的属性
 - 2.Put: 添加新的一行，或者更新已有的行
 - 3.Scans:多行数据扫描
 - 4.Delete:从表中移除一行

##2.物理存储
这一章节主要介绍HBase如何存储数据。

`1.Table中的所有行都按照row key 的字典序排列`
`2.Table在行的方向分割为多个HRegion`

![](/images/hbase_pic_2.png)

`3.region按大小分割的，每一个表一开始只有一个region,随着数据的不断插入，region不断增大，当增大到一个阈值的时候，HRegion就会分成两个新的region,随着数据的插入，Region会越来越多。`

![](/images/hbase_pic_3.png)

`4.HRegion是HBase中分布式的存储和负载均衡的最小单元，最小单元就表示不同的HRegion可以分布在不同的HRegionServer 上，但一个HRegion是不会拆分到多个 server上的。`

![](/images/hbase_pic_4.png)

`5. HRegion虽然是分布式存储的最小单元，但不是存储的最小单元
实际上，HRegion由一个或多个Store组成，每个Store由一个MemStore和0或多个StoreFile 组成，其中，StoreFile是以HFile的格式保存在HDFS上。`

###2.1HFile的组成
下图是HFile的组成部分:

![Alt text](/images/hbase_pic_5.png)

主要有以下几个部分:

- 1.Scanned block section:存储数据块的部分
- 2.Non-Scanned block section:元数据block部分，主要存放Meta信息，及bloomFilter的信息。
- 3.Load-on-open-section:这部分数据在RegionServer启动时，实例化Region并创建HStore时会将所有的StoreFile的Load-on-open-section 加载进内存，主要存放了Root Data Index,meta Index,File Info,BloomFilter的MetaData 等，除了Fields for midkey外，每部分都是一个HFileBlock。
- 4.trailer:文件尾，主要纪录 version版本。

`下面重点介绍load-on-open-section`:

RegionServer管理0...N个Region,Region管理一个或多个HStore,其中HStore就管理一个MemStore和多个StoreFile.

 当RegionServer启动时，会扫描所有的StoreFile,加载StoreFile的相关信息到内存，而这部分内容就是load-on-open-section,主要包含Root数据索引，midkey(optional),Meta索引，File Info及BloomFilter metadata 等。

下面是HFile 的一个基本结构图:

![Alt text](/images/hbase_pic_6.png)

我们可以看一下key-value 的内部结构：

![Alt text](/images/hbase_pic_7.png)

####2.1.1 数据索引

数据索引是分层的，1-3 层。

- 第一层,即Root level Data Index,这部书数据存储在内存区的，一开始文件较小，至于欧single-level,rootIndex  直接定位到数据块了，当StoreFile变大时，rootIndex越来越大，随之消耗的内存也越大，会以多层结构存储数据索引。

- 第二层，当采用multi-level方式，使用root Index 和leaf Index chunk ,及内存区的rootIndex定位到leafIndex ,再由leafIndex 定位到Datablock

- 第三层，当一个文件的datablock非常多，采用三级索引，由rootIndex定位到intermediateIndex，再由intermediate index定位到leaf index,但每一部分Index都是以HFileBlock格式存放的。

####2.1.2 Fields for midkey

这部分数据是Optional的，保存了一些midkey的信息，可以快速定位到midkey,常常在HFileSplit的时候是非常有用的。

####2.2.3 MetaIndex FileInfo

MetaIndex:meta的索引数据，和data index 类似，但是meta存放的是BloomFilter的信息。
FileInfo: 保存了一些文件的信息，如lastkey,avgkey,avgValueLen等。

##3. HBase架构

下面一幅图是hadoop生态圈的架构：

![Alt text](/images/hbase_pic_8.png)

下面是HBase架构图:
![Alt text](/images/hbase_pic_9.png)

下面是HBase组件的介绍:

**Client:**

- 1.使用RPC机制与HMaster和HRegionServer 进行通信
- 2.Client 与HMaster通信管理类操作
- 3.Clinet 与HRegion进行数据读写类操作

**zookeeper:**

- 1.Zookeeper Quorum存储-ROOT- 表地址，HMaster地址
- 2.HRegionServer把自己以Ephedral方式注册到Zookeeper中，HMaster随时感知各个HRegionServer的健康状况

**HMaster:**

- 1.管理用户对表的增删改查的操作
- 2.管理 HRegion的负载均衡，调整 Region的分布
- 3.HRegionServer停机后，负责迁移

**HRegionServer**:

HBase的最核心模块，主要负责用户IO响应，向HDFS文件系统读写数据。
下面是 RegionServer的架构图：

![Alt text](/images/hbase_pic_10.png)

- 1.每一个HRegionServer管理一些列HRegion对象
- 2.每一个HRegion对象对应Table的一个Region,HRegion包含多个HStore
- 3.每一个HStrore对应Table的一个Column Family的存储
- 4.HStore是HBase的存储核心，由MemStore和StoreFile组成


##4.HBase写过程

写入数据基本过程:

- 1.客户端写入数据,找到需要写入的 regionServer和对应的region(根据row key)
- 2.存入MemStore
- 3.当MemStore满，flush成一个StoreFile
- 4.当storeFile数量增长到一定阈值，触发compact合并操作以及数据删除
- 5.当StoreFiles Compact后，逐步越来越大
- 6.当 单个StoreFile大小超过一定阈值，触发split操作，把当前的Region split成两个Region,Region会下线，新split的region会被HMaster分配到相应的HRegionServer上。

从上面可以看到，Hbase只是增加数据，所有更新和删除操作在compact阶段做。所以用户写操作只需要进入到内存即可返回，从而保存IO 性能。

###4.1 HLog

在分布式系统的环境中，无法避免系统出错或者宕机，一旦HRegionServer意外退出， MemStore中的内存数据就会丢失，引入HLog就是防止这种情况。

**工作机制**：

```
每一个 HRegionServer中都会有一个HLog对象，HLog是一个**Write Ahead Log**的类，每次用户操作写入MemStore 的同时，也会写一份数据到HLog文件，HLog文件会定时滚动出新，并删除旧的文件。当HRegionServer意外终止后，HMaster会通过Zookeeper感知，HMaster首先处理遗留的Log文件，将不同的region的log数据拆分 ，分别放到相应的region目录下,然后再将失效的region重新分配，得到这些region的HRegionServer再Load Region的过程中，会发现有历史的HLog文件需要处理，因此会Replay Hlog中的数据到MemStore中，然后flush到StoreFiles,完成数据恢复。
```

###4.2写缓存

每一个put操作实际上就是RPC 操作，它将客户端的数据传送到服务器然后返回，这只适合小数据量的操作。如果需要每秒存储上千行的数据到Hbase表中，HBase的API配备了一个客户端的写缓冲区，缓冲区负责put操作，然后调用RPC一次性讲put送往服务器，默认情况下，客户端的缓冲区是禁止的。

激活缓冲区：`table.setAutoFlush(false);void flushCommits()`
配置写缓存区大小：`void setWritableBufferSize(long writeBufferSzie)`


##5.HBase读过程











